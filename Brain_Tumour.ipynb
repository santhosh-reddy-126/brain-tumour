{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "98b444a8-afce-4b71-a963-e9234e40da97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290e08e0-08f6-4b7b-b043-fa05506bfbeb",
   "metadata": {},
   "source": [
    "# Preprocessing The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aeb4582a-601e-4e4c-82db-b3582eec7c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4213 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                            shear_range=0.2,\n",
    "                            zoom_range=0.2,\n",
    "                            horizontal_flip=True)\n",
    "train_dataset = train_datagen.flow_from_directory('archive/Brain_Tumor_Dataset',target_size=(64,64),batch_size=32,class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3263896b-b5de-4a17-b7da-70262f02924e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1053 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_dataset = test_datagen.flow_from_directory('test',target_size=(64,64),batch_size=32,class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd09d33-8523-44aa-9c8c-92a8be2b340a",
   "metadata": {},
   "source": [
    "# Lets Build the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "89ecfd97-0a53-4a55-8d77-64a5b2ba1499",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "14069680-8f4f-4479-a6d7-6aa3a9d1f1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_Shape=(64,64,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6fb1f8a0-b52c-418b-9ee4-b60b9d8ed194",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Input(shape=Input_Shape))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c9512714-30f5-4561-9a8b-51cadfcb34fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "76007a5b-736b-48d1-bec8-52698211319d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation=\"relu\"))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9a50df82-48ac-4ad6-b603-e194531f6bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d5c016d6-bbae-4aa5-9209-760a445f00b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=150,activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4eac43fb-8978-4167-a5c9-c0f583db8dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=50,activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7213afa9-8a91-4787-bb13-234fd18ebdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=1,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d3397a09-0ccb-4726-937e-e6c3ad0ca2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "593f7ba2-4eb6-48fc-8919-4a44d5665307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santh\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 469ms/step - accuracy: 0.7957 - loss: 0.4245 - val_accuracy: 0.7768 - val_loss: 0.4736\n",
      "Epoch 2/30\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 182ms/step - accuracy: 0.9082 - loss: 0.2370 - val_accuracy: 0.9326 - val_loss: 0.2100\n",
      "Epoch 3/30\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 192ms/step - accuracy: 0.9435 - loss: 0.1452 - val_accuracy: 0.8557 - val_loss: 0.3528\n",
      "Epoch 4/30\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 206ms/step - accuracy: 0.9518 - loss: 0.1318 - val_accuracy: 0.8984 - val_loss: 0.2490\n",
      "Epoch 5/30\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 198ms/step - accuracy: 0.9562 - loss: 0.1129 - val_accuracy: 0.9012 - val_loss: 0.2442\n",
      "Epoch 6/30\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 173ms/step - accuracy: 0.9623 - loss: 0.1019 - val_accuracy: 0.9497 - val_loss: 0.1352\n",
      "Epoch 7/30\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 176ms/step - accuracy: 0.9660 - loss: 0.0940 - val_accuracy: 0.9753 - val_loss: 0.0769\n",
      "Epoch 8/30\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 192ms/step - accuracy: 0.9612 - loss: 0.0977 - val_accuracy: 0.9117 - val_loss: 0.2106\n",
      "Epoch 9/30\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 197ms/step - accuracy: 0.9777 - loss: 0.0711 - val_accuracy: 0.9706 - val_loss: 0.0797\n",
      "Epoch 10/30\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 212ms/step - accuracy: 0.9764 - loss: 0.0719 - val_accuracy: 0.9649 - val_loss: 0.1141\n",
      "Epoch 11/30\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 183ms/step - accuracy: 0.9727 - loss: 0.0640 - val_accuracy: 0.9687 - val_loss: 0.0903\n",
      "Epoch 12/30\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 199ms/step - accuracy: 0.9789 - loss: 0.0557 - val_accuracy: 0.9582 - val_loss: 0.1310\n",
      "Epoch 13/30\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 199ms/step - accuracy: 0.9773 - loss: 0.0597 - val_accuracy: 0.9430 - val_loss: 0.1732\n",
      "Epoch 14/30\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 214ms/step - accuracy: 0.9782 - loss: 0.0560 - val_accuracy: 0.9715 - val_loss: 0.0953\n",
      "Epoch 15/30\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 178ms/step - accuracy: 0.9852 - loss: 0.0504 - val_accuracy: 0.9706 - val_loss: 0.0615\n",
      "Epoch 16/30\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 187ms/step - accuracy: 0.9880 - loss: 0.0392 - val_accuracy: 0.9734 - val_loss: 0.0659\n",
      "Epoch 17/30\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 196ms/step - accuracy: 0.9908 - loss: 0.0266 - val_accuracy: 0.9544 - val_loss: 0.1316\n",
      "Epoch 18/30\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 214ms/step - accuracy: 0.9902 - loss: 0.0279 - val_accuracy: 0.9839 - val_loss: 0.0461\n",
      "Epoch 19/30\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 180ms/step - accuracy: 0.9908 - loss: 0.0279 - val_accuracy: 0.9810 - val_loss: 0.0643\n",
      "Epoch 20/30\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 188ms/step - accuracy: 0.9900 - loss: 0.0279 - val_accuracy: 0.9022 - val_loss: 0.3173\n",
      "Epoch 21/30\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 198ms/step - accuracy: 0.9905 - loss: 0.0341 - val_accuracy: 0.9858 - val_loss: 0.0523\n",
      "Epoch 22/30\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 203ms/step - accuracy: 0.9952 - loss: 0.0150 - val_accuracy: 0.9858 - val_loss: 0.0650\n",
      "Epoch 23/30\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 227ms/step - accuracy: 0.9941 - loss: 0.0211 - val_accuracy: 0.9345 - val_loss: 0.1840\n",
      "Epoch 24/30\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 182ms/step - accuracy: 0.9927 - loss: 0.0208 - val_accuracy: 0.9886 - val_loss: 0.0367\n",
      "Epoch 25/30\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 174ms/step - accuracy: 0.9936 - loss: 0.0178 - val_accuracy: 0.9753 - val_loss: 0.0895\n",
      "Epoch 26/30\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 198ms/step - accuracy: 0.9933 - loss: 0.0195 - val_accuracy: 0.9886 - val_loss: 0.0506\n",
      "Epoch 27/30\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 208ms/step - accuracy: 0.9954 - loss: 0.0177 - val_accuracy: 0.9430 - val_loss: 0.1738\n",
      "Epoch 28/30\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 215ms/step - accuracy: 0.9935 - loss: 0.0169 - val_accuracy: 0.9943 - val_loss: 0.0283\n",
      "Epoch 29/30\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 185ms/step - accuracy: 0.9992 - loss: 0.0050 - val_accuracy: 0.9269 - val_loss: 0.2695\n",
      "Epoch 30/30\n",
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 206ms/step - accuracy: 0.9961 - loss: 0.0185 - val_accuracy: 0.9953 - val_loss: 0.0214\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x233a09471d0>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(x=train_dataset,validation_data=test_dataset,epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "fa9ff567-efd2-4761-8153-a46487895984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "test_image = image.load_img('ext/pos3.jpg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image,axis=0)\n",
    "result = cnn.predict(test_image)\n",
    "prediction=\"\"\n",
    "if result[0][0]==0:\n",
    "    prediction=\"Negative\"\n",
    "else:\n",
    "    prediction=\"Positive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f8f863e9-9cbe-4a1f-bfb0-052f410c8525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.]], dtype=float32)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2787a595-053b-42c9-a81f-745ac0475ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "keras.saving.save_model(cnn,\"Brain_Tumour.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465341ae-c45d-4edb-8ac6-3cba9cae3f98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
